{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4w3IC-Qvcyq"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222046,
     "status": "ok",
     "timestamp": 1615451967224,
     "user": {
      "displayName": "Ryan",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -480
    },
    "id": "4U1yFOTSM5Jw",
    "outputId": "5e7b5f5c-88ed-40ff-f025-4c28bff1fd43"
   },
   "outputs": [],
   "source": [
    "import sys; \n",
    "import ast\n",
    "from glob import glob\n",
    "import cv2\n",
    "from skimage import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from contextlib import contextmanager\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold, KFold\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import timm\n",
    "import warnings\n",
    "import joblib\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import nibabel as nib\n",
    "import pydicom as dicom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6YIAKXXe81-"
   },
   "source": [
    "# helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../kingston'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store segmentation paths in a dataframe\n",
    "seg_paths = glob(f\"{datadir}/segmentations/*\")\n",
    "seg_df = pd.DataFrame({'path': seg_paths})\n",
    "seg_df['StudyInstanceUID'] = seg_df['path'].apply(lambda x:x.split('/')[-1][:-4])\n",
    "seg_df = seg_df[['StudyInstanceUID','path']]\n",
    "print('seg_df shape:', seg_df.shape)\n",
    "seg_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    img = dicom.dcmread(path)\n",
    "    img.PhotometricInterpretation = 'YBR_FULL'\n",
    "    data = img.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return cv2.cvtColor(data, cv2.COLOR_GRAY2RGB), img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_uid_list = seg_df[\"StudyInstanceUID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list = []\n",
    "os.makedirs(f\"{datadir}/seg_25d_image\", exist_ok=True)\n",
    "os.makedirs(f\"{datadir}/seg_25d_mask\", exist_ok=True)\n",
    "\n",
    "for file_name in tqdm(study_uid_list):\n",
    "    ex_path = f\"{datadir}/segmentations/{file_name}.nii\"\n",
    "    mask = nib.load(ex_path)\n",
    "    mask = mask.get_fdata()  # convert to numpy array\n",
    "    mask = mask[:, ::-1, ::-1].transpose(1, 0, 2)\n",
    "    mask = np.clip(mask,0,8).astype(np.uint8)\n",
    "    mask = np.ascontiguousarray(mask)\n",
    "\n",
    "    train_image_path = glob(f\"{datadir}/train_images/{file_name}/*\")\n",
    "    train_image_path = sorted(train_image_path, key=lambda x:int(x.split(\"/\")[-1].replace(\".dcm\",\"\")))\n",
    "    image_list = []\n",
    "    for path in train_image_path:\n",
    "        im, meta = load_dicom(path)\n",
    "        image_list.append(im[:,:,0])\n",
    "    image = np.stack(image_list, axis=2)\n",
    "    \n",
    "    assert image.shape == mask.shape, f\"Image and mask {file_name} should be the same size, but are {image.shape} and {mask.shape}\"\n",
    "    slice_num = image.shape[2]\n",
    "\n",
    "    for i in range(1, slice_num-1):\n",
    "        image_25d = image[:,:, i-1:i+2]\n",
    "        mask_25d = mask[:,:, i-1:i+2]\n",
    "        assert image_25d.shape == mask_25d.shape == (512, 512, 3), f\"Image and mask {file_name} should be (512, 512, 3), but are {image_25d.shape} and {mask_25d.shape}\"\n",
    "        image_save_path = f\"{datadir}/seg_25d_image/{file_name}_{i}.npy\"\n",
    "        mask_save_path =  f\"{datadir}/seg_25d_mask/{file_name}_{i}.npy\"\n",
    "        np.save(image_save_path, image_25d)\n",
    "        np.save(mask_save_path, mask_25d)\n",
    "        dataframe_list.append([f\"{file_name}_{i}\", file_name, i, image_save_path, mask_save_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_25d_df = pd.DataFrame(dataframe_list, columns=[\"id\", \"StudyInstanceUID\", \"slice_num\", \"image_path\", \"mask_path\"])\n",
    "seg_25d_df[\"fold\"] = -1\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for idx, (train_index, test_index) in enumerate(gkf.split(X=seg_25d_df, groups=seg_25d_df['StudyInstanceUID'].values)):\n",
    "    seg_25d_df.loc[test_index, 'fold'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    study_num = len(np.unique(seg_25d_df[seg_25d_df[\"fold\"] == i][\"StudyInstanceUID\"]))\n",
    "    print(f\"fold{i} num: {study_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_25d_df.to_csv(f\"{datadir}/seg_25d.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 ---> background   \n",
    "1 ---> C1   \n",
    "2 ---> C2   \n",
    "...     \n",
    "8 ---> T1 - T12  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "【V】stage1.ipynb",
   "provenance": [
    {
     "file_id": "1_ekPHJkRCuHI-A_DNUuSPRXVbsLdlZ5k",
     "timestamp": 1611044390026
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b79a61544c9a744d09395b396d14bdc3ab2980641b64ddb1c7bc6d7b892900a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
